---
title: "Delhi temperature timeseries data SARIMA model fitting"
output:
  pdf_document: default
  html_document: default
---

Here we are doing a time-series analysis of the daily temperature in the city of Delhi for the period of Jan 01, 1995 to Dec 31, 2019.

```{r include = FALSE}
library(zoo)
library(tidyr)
library(dplyr)
library(lubridate)
library(astsa)
library(forecast)
```

**Reading the data**

```{r}
DelhiTemp <- read.csv(file = '../../../Data/Delhi_temperature_1995_2020.csv')
```

**Viewing the data**

```{r}
head(DelhiTemp)
```

Creating a date column from Month, Day and Year columns.

```{r}
DelhiTemp$Date <- as.Date(with(DelhiTemp, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
```

Temperature vs. Date plot

```{r}
Temp <- DelhiTemp$Temperature
Date <- DelhiTemp$Date
plot(Temp~Date)
```
Our data shows clear yearly seasonality and their are some very large outliers (temperature~-100) possibly because of missing data for those dates.

### Outlier detection and missing value treatment

Identifying outliers and replacing them with backfilled values:

```{r}
DelhiTemp$Temperature[DelhiTemp$Temperature < 0] <- NA
which(is.na(DelhiTemp$Temperature))
DelhiTemp$Temperature <- na.locf(DelhiTemp$Temperature, fromLast = TRUE)
which(is.na(DelhiTemp$Temperature))
```

**Updated Temperature vs. Date plot**

```{r}
Temp <- DelhiTemp$Temperature
Date <- DelhiTemp$Date
plot(Temp~Date)
```

### Binning

Binning temperatures to their mean monthly values

```{r}
DelhiMonthlyTemp <- DelhiTemp %>% group_by(Year,Month) %>% summarize(Temperature = mean(Temperature))

head(DelhiMonthlyTemp);
```

Setting a new date column with just the month and year info

```{r}
DelhiMonthlyTemp$Date <- as.yearmon(paste(DelhiMonthlyTemp$Year, DelhiMonthlyTemp$Month), "%Y %m")
```

**Monthly mean temperature vs. Date (Month) plot**

```{r}
Temp <- DelhiMonthlyTemp$Temperature
Date <- DelhiMonthlyTemp$Date
plot(Temp~Date,type="l")
```

Once again we see that the data shows clear seasonality but no variation in variance so differencing should be enough for taking care of the trend.

### ACF and PACF plots

Let's first look at the auto-correlation function and the partial auto-correlation function plots.

```{r}
Temp <- DelhiMonthlyTemp$Temperature

par(mfrow=c(2,1))
acf(Temp,main='ACF')
pacf(Temp,main='PACF');
```

We see that the ACF also shows clear seasonality.

## Guessing the right orders for (S)ARIMA model fitting

1. Differncing orders (d, D)

Non-seasonal and seasonal differencing -> *diff(diff(data),12)*

```{r}
plot(diff(diff(Temp),12),type="l")
```

the plot shows almost no-trends except for a few large peaks at the center which may be outliers => d=1, D=1. We can also use the AD Fuller test for checking the stationarity

```{r}
#diff_data <- diff(diff(Temp),12)
#adf.test(diff_data)
```

The test confirms that the data is stationary.

2. orders for the auro-regressive (AR) and Moving Average (MA) terms i.e. p and q

**ACF and PACF for differenced data**

```{r}
par(mfrow=c(2,1))
acf(diff(diff(Temp),12),main='differnced data ACF',50)
pacf(diff(diff(Temp),12),main='differnced data PACF',50);
```

The ACF plot shows significant correlations at lag=1,11 and 12 while the PACF shows significant correlation for lag=1,11 and 12 The correlations at later parts may be due to seadonality

### Finding best parameters using
1. Grid Search

Trying for different values of p,q,P,Q and note down AIC, SSE and p-value (for Ljun-box-test). 
We want high p-values and small AIC and SSE using parsimony principle (simpler the better) while searching

```{r}
d=1; DD=1; per=12

for(p in 1:2){
  for(q in 1:2){
    for(i in 1:6){
      for(j in 1:3){
        if(p+d+q+i+DD+j<=10){
          
          model<-arima(x=Temp, order = c((p-1),d,(q-1)), seasonal = list(order=c((i-1),DD,(j-1)), period=per))
          
          pval<-Box.test(model$residuals, lag=log(length(model$residuals)))
          
          sse<-sum(model$residuals^2)
          
          cat(p-1,d,q-1,i-1,DD,j-1,per, 'AIC=', model$aic, ' SSE=',sse,' p-VALUE=', pval$p.value,'\n')
          
        }
      }
    }
  }
}
```

2. Using auto.arima()

```{r}
y <- msts(Temp, seasonal.periods=c(12))
auto.arima( y, d = 1, D = 1,  max.p = 5,  max.q = 5,  max.P = 5,  max.Q = 5, max.order = 10,  start.p = 1,  start.q = 1,  start.P = 0, start.Q = 0, stationary = FALSE, seasonal = TRUE, ic="aic", stepwise = TRUE, approximation = FALSE)
```



### Best-model

For some reason auto-arima is unable to reproduce the minimum value of AIC which was found in the grid-search method. From the grid-search the lowest AIC of 1221.998 is found for a 1,1,1,0,1,1,12 SARIMA model which also has a large enough p-value.

### SARIMA(1,1,1,0,1,1,12) fitting results

```{r}
sarima(Temp,1,1,1,0,1,1,12);
```
We see that the residuals are almost stationary and there is not much correlation left in the lags of the residuals, also the p-value of the Ljung-Box test is significant at almost all lags.

### Forecasting using the best-model

```{r}
model<-arima(x=Temp, order = c(1,1,1), seasonal = list(order=c(0,1,1), period=per))
par(mfrow=c(1,1))
plot(forecast(model,12)); # forecasting for the 12 months after the end of the dataset
```

